\documentclass[12pt, oneside, final]{report}
\usepackage{geometry}
\geometry{a4paper, left=20mm, right=20mm, top=25mm, bottom=25mm}
\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[MeX]{polski}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{indentfirst}
\usepackage{pdfpages}
\usepackage{listings, xcolor}
\usepackage{colortbl}
\usepackage{placeins} % provides \FloatBarrier
\usepackage{tikz}
\usepackage{minted}
\usepackage{lscape}
\usetikzlibrary{positioning,shapes,arrows,calc,decorations.markings,shadows}
\usepackage[hidelinks]{hyperref}

%listing kodu
\lstset{
	mathescape,
               numbersep=5pt,
               frame=lines,
               framesep=2mm,
               breaklines,
    string=[s]{"}{"},
    stringstyle=\color{blue},
    comment=[l]{:},
    commentstyle=\color{black},
}

% Czcionka
\usepackage{charter}

% Pojedyncze elementy na górze stron
\makeatletter
\setlength{\@fptop}{0pt}
\makeatother

% Styl tytułowania rozdziałów:
\usepackage{titlesec}
%\titleformat{\chapter}{\normalfont\huge}{\bf\thechapter.}{20pt}{\huge\bf}
% Styl tytułowania rozdziałów:
\titleformat{\chapter}[display]
{\centering\normalfont\huge\bfseries}{\centering\chaptertitlename\ \thechapter.}{0.5em}{}
\titlespacing{\chapter}{0em}{0em}{2em}

% dodatkowe kropki po numerach rozdziałów, sekcji itd
\usepackage{titlesec}
\titlelabel{\thetitle.\quad}

% Dodatkowe odstępy w tabelach
\usepackage{array}
\setlength\extrarowheight{4pt}

% Wyłączone wcięcia
\usepackage{parskip}

\begin{document}
% Title page
\begin{titlepage}
	\centering
	\begin{figure}
		\centering
		\includegraphics[width=0.9\textwidth]{logo.pdf}
	\end{figure}
	\vspace*{60pt}
	\Large{Systemy agentowe}\\
	\Large{Wstęp do eksploracji danych tekstowych w sieci WWW}\\
	\vspace{60pt}
	\textsc{\Huge{System przeszukiwania projektów open source na podstawie danych z repozytoriów kodu}}\\
	\vspace{20pt}
	\large{Sprawozdanie z projektu}\\
	\vspace{120pt}
	\Large{Paweł Karwacki \textit{259820}}\\
	\Large{Maciej Krasowski \textit{259831}}\\
	\Large{Łukasz Kilaszewski \textit{259822}}\\
	\vfill
	\large{28 maja 2018}
\end{titlepage}

\thispagestyle{empty}
%\tableofcontents
%\cleardoublepage

\section*{Wstęp}
Podstawowym założeniem projektu było przygotowanie systemu agentowego, który będzie w stanie przeszukiwać projekty open source. Po podaniu wyszukiwanej frazy, system miał zwracać listę najbardziej dopasowanych projektów wraz z odnośnikami prowadzącymi do repozytoriów.

Całość projektu została napisana w języku Python 3. Do zaprojektowania systemu agentowego wykorzystano bibliotekę Pulsar, natomiast do zadań związanych z przetwarzaniem tekstu użyty zostały biblioteki Nltk (tokenizacja, stemming, itp.) oraz Gensim (budowa słownika oraz modeli i indeksów). Kod źródłowy przygotowanego rozwiązania dostępny jest pod adresem \url{https://github.com/luktor99/SAG-WEDT}.

\section*{Dane do przeszukiwania}
Jako źródło danych do przeszukiwania wybraliśmy platformę GitHub, głównie ze względu na ilość zgromadzonych tam publicznych repozytoriów oraz dostępność darmowego interfejsu API. Niestety interfejs ten posiada ograniczenie w postaci limitu 5000 zapytań na godzinę. Ponadto, pobieranie repozytoriów w czasie rzeczywistym wiąże się z dużym spowolnieniem działania systemu ze względu na opóźnienia generowane przez liczne zapytania HTTP.

Biorąc pod uwagę powyższe niedogodności, zdecydowaliśmy się na wcześniejsze pobranie pewnej puli repozytoriów. Dzięki temu właściwa aplikacja może uzyskiwać dostęp do wielu repozytoriów z minimalnymi opóźnieniami. Aby wybrać najbardziej interesujące repozytoria, pobieranie obejmuje te o największej ilości "gwiazdek", czyli najbardziej wartościowe z punktu widzenia społeczności serwisu GitHub. Dane składowane są w folderze projektu w folderze \texttt{gh-database}. Za pobieranie oraz dostęp do zapisanych repozytoriów odpowiada klasa \texttt{GHInterface}, której implementacja znajduje się w pliku \texttt{src/ghinterface.py}.

Ilość pobranych repozytoriów może być ustawiana za pomocą parametru \texttt{top\_repos\_to\_down\-load} w pliku \texttt{src/config.py}. Domyślnie wynosi ona 10000, co daje 100 plików z danymi po 100 repozytoriów w każdym.

\section*{Dostosowanie biblioteki Pulsar do wymogów projektu}
Analiza zadań koniecznych do wykonania w kolejnych etapach pozwoliła zauważyć, że są one podobne do siebie i wpisują się w jeden schemat -- istnieje zbiór niezależnych od siebie zadań, które mogą być wykonywane równolegle. Na podstawie tego spostrzeżenia przygotowana została klasa \texttt{Agency} (znajdująca się w pliku \texttt{src/Agency.py}), która dostarcza uniwersalny interfejs dla inicjalizacji i finalizacji agentów oraz rozdzielania zadań pomiędzy nich. Zbudowany na bazie tej klasy system pozwala na równoległe wykonywanie wielu zadań oraz jest odporny na uszkodzenie jednego z nich (przy czym może prowadzić do wybrakowania wyników).
\\
Po utworzeniu instancji klasy \texttt{Agency} arbiter (w bibliotece Pulsar jest to główny agent) tworzy określoną liczbę agentów potomnych i oczekuje na zakończenie ich inicjalizacji, zazwyczaj jest to ustawienie zmiennych i skopiowanie ich do atrybutu (słownika) klasy \texttt{Actor} - \texttt{extra}. Dzięki temu każdy agent ma swoje podręczne dane, gdzie zależnie od przypadku może przechowywać swoją kopię słownika oraz wyniki pracy. W momencie zakończenia inicjalizacji arbiter przydziela agentom zadania z listy zadań do wykonania. Jeśli jakiś agent zakończy swoją pracę wysyła wiadomość do arbitra i oczekuje na nowe zadanie. W przypadku, gdy arbiter nie ma już zadań do rozdysponowania agent wykonuje swoje ostatnie zadanie (podane jako parametr do klasy - zazwyczaj wiąże się to z przesłaniem wyników pracy danego agenta do arbitra). Ostatnim etapem przetwarzania agentowego jest podsumowanie wyników od poszczególnych agentów przez arbitra.

\section*{Przygotowanie modeli i plików do przeszukiwania}
Przygotowanie ściągniętych wcześniej informacji o repozytoriach do przeszukiwania wymagało przeprowadzenie kilkuetapowego przetwarzania. Każdy etap wykonywany jest przez osobny skrypt, z których każdy tworzony był w oparciu o klasę Agency. Były to kolejno:
\begin{itemize}
	\item{Tokenizacja plików readme, stemming powstałych tokenów oraz utworzenie słownika na bazie ztokenizowanych dokumentów.}
	\item{Konwersja ztokenizowanych dokumentów do wektorów bag-of-words na bazie słownika oraz utworzenie modelu TFIDF (term frequency, inverse document frequency), który ma na celu uwzględnienie wartości informacyjnej poszczególnych słów w tekście.}
	\item{Konwersja wektorów bag-of-words do przestrzeni TFIDF na bazie modelu TFIDF oraz utworzenie modelu LSI (Latent Semantic Indexing), który ogranicza wielkość rozważanej przestrzeni (w tym przypadku do 400) i kojarzy słowa semantycznie.}
	\item{Konwersja wektorów TFIDF do przestrzeni LSI oraz zaindeksowanie powstałych wektorów w celu znacznego przyspieszenia wyszukiwania.}
\end{itemize}

Szczególnie interesujący był punkt pierwszy, bowiem właściwa tokenizacja okazała się bardziej problematyczna, niż można było się tego spodziewać. Po pierwsze należało przekonwertować format markdown (typowy dla plików readme) do czystego tekstu. W pierwotnej wersji później następowała tokenizacja, filtracja, stemming i usunięcie \textit{stop words}. Pierwsze wyniki wyszukiwania pokazały jednak, że chińskie repozytoria psują jakość wyszukiwania. Aby poradzić sobie z tym problemem usunięto wszystkie te repozytoria, dla których liczba słów zawierających znaki nietypowe przekracza 5\%.

\section*{Dopasowywanie dokumentów do zapytania}
Na początku użytkownik proszony jest o wpisanie zapytania. Następnie arbiter przekształca zapytanie do przestrzeni LSI oraz zaczyna tworzenie poszczególnych agentów z wykorzystaniem klasy \texttt{Agency},  następnie rozdziela pracę pomiędzy agentami.
Każdy z tworzonych agentów przetwarza przydzielone pliki i dopasowuje zaindeksowane w nich readme do przekazanego zapytania. Dokonuje też na bieżąco sortowania wszystkich dotychczas uzyskanych przez siebie wyników.
\\
Po przetworzeniu wszystkich dokumentów wszystkie agenty są proszone o przesłanie wyników swojej pracy. Na koniec arbiter dokonuje sortowania wyników i przedstawia 20 najlepszych rozwiązań (ten parametr można zmienić w pliku konfiguracyjnym \texttt{src/config.py}).

\section*{Wyniki działania systemu}
Po uruchomieniu aplikacji użytkownik proszony jest o wpisanie szukanej frazy (np. \texttt{tensorflow}) - przykłady wyników działania systemu dla tego zapytania znajdują się w załącznikach na końcu sprawozdania. W trakcie działania system wyświetla w postaci logów informacje diagnostyczne informujące co aktualnie jest wykonywane i przez którego agenta. W przypadku, gdy jakiś agent zostanie awaryjnie zatrzymany zostanie wyświetlona odpowiednia informacja. W takim przypadku (zgodnie z założeniami) część pracy wykonanej przez tego agenta zostanie stracona. Ze względu jednak na prawdopodobieństwo takiego zdarzenia oraz znaczne rozproszenie pracy w trakcie eksperymentów nie zaobserwowano drastycznego pogorszenia się wyników działania systemu. Rezultat wyszukiwania pokazywany jest także w postaci logów, które są uporządkowane malejąco względem dopasowania frazy do pliku readme.

\section*{Wnioski}
Jak pokazano w załączonych na końcu sprawozdania logach aplikacyjnych system jest odporny na zabicie jednego z agentów. Jest to immanentna cecha dobrych systemów agentowych. Dzięki temu, że dane są rozproszone i każdy z agentów ma pewną autonomię zadanie jest wykonywalne w sposób bezpieczniejszy oraz potencjalnie szybszy. Struktura większości modułów systemu (od przygotowywania modeli języków do samego przeszukiwania repozytoriów) jest bardzo podobna. Ten fakt został wykorzystany i stworzono generyczną klasę \texttt{Agency}, która dzięki zadaniu odpowiednich parametrów była dopasowywana do wykonywania określonego zadania.
\\
Dostosowanie biblioteki Pulsar do tego zadania nastręczyło sporo trudności. Wynika to z faktu, że nie służy ona bezpośrednio do tworzenia systemów agentowych, a wykorzystuje te mechanizmy. Kolejną przyczyną jest słaba dokumentacja, która dostępna jest w wielu wersjach (nie wszystkie są aktualne) oraz posiada zaledwie kilka bardzo prostych przykładów komunikacji między agentami.

\begin{landscape}
Przykład 1: Wyniki wyszukiwania frazy \texttt{tensorflow} (wszystkie agenty prawidłowo zakończyły działanie):

\begin{minted}[mathescape,
               linenos,
               numbersep=5pt,
               %frame=lines,
               framesep=3mm,
               xleftmargin=21pt,
               breaklines,
               fontsize=\footnotesize]{js}

{'name': 'jtoy/awesome-tensorflow', 'url': 'https://github.com/jtoy/awesome-tensorflow', 'score': 0.91692072}

{'name': 'tensorflow/skflow', 'url': 'https://github.com/tensorflow/skflow', 'score': 0.88495779}

{'name': 'deepmind/sonnet', 'url': 'https://github.com/deepmind/sonnet', 'score': 0.88260406}
{'name': 'tensorflow/tensorflow', 'url': 'https://github.com/tensorflow/tensorflow', 'score': 0.87205422}
{'name': 'astorfi/TensorFlow-World', 'url': 'https://github.com/astorfi/TensorFlow-World', 'score': 0.8399685}
{'name': 'tensorflow/models', 'url': 'https://github.com/tensorflow/models', 'score': 0.8325097}
{'name': 'nfmcclure/tensorflow_cookbook', 'url': 'https://github.com/nfmcclure/tensorflow_cookbook', 'score': 0.76908624}
{'name': 'tensorflow/fold', 'url': 'https://github.com/tensorflow/fold', 'score': 0.76521885}
{'name': 'tflearn/tflearn', 'url': 'https://github.com/tflearn/tflearn', 'score': 0.75520557}
{'name': 'yahoo/TensorFlowOnSpark', 'url': 'https://github.com/yahoo/TensorFlowOnSpark', 'score': 0.74378902}
{'name': 'tensorflow/serving', 'url': 'https://github.com/tensorflow/serving', 'score': 0.72587609}
{'name': 'samjabrahams/tensorflow-on-raspberry-pi', 'url': 'https://github.com/samjabrahams/tensorflow-on-raspberry-pi', 'score': 0.72068191}
{'name': 'tensorflow/swift', 'url': 'https://github.com/tensorflow/swift', 'score': 0.7169168}
{'name': 'vahidk/EffectiveTensorflow', 'url': 'https://github.com/vahidk/EffectiveTensorflow', 'score': 0.69827163}
{'name': 'leriomaggio/deep-learning-keras-tensorflow', 'url': 'https://github.com/leriomaggio/deep-learning-keras-tensorflow', 'score': 0.69624388}
{'name': 'pkmital/tensorflow_tutorials', 'url': 'https://github.com/pkmital/tensorflow_tutorials', 'score': 0.65139794}
{'name': 'chiphuyen/stanford-tensorflow-tutorials', 'url': 'https://github.com/chiphuyen/stanford-tensorflow-tutorials', 'score': 0.63101554}
{'name': 'aymericdamien/TensorFlow-Examples', 'url': 'https://github.com/aymericdamien/TensorFlow-Examples', 'score': 0.62967598}
{'name': 'jostmey/NakedTensor', 'url': 'https://github.com/jostmey/NakedTensor', 'score': 0.6064766}
{'name': 'CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial', 'url': 'https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial', 'score': 0.60384893}

\end{minted}
\end{landscape}

\begin{landscape}
Przykład 2: Wyniki wyszukiwania frazy \texttt{tensorflow} (jeden z agentów został awaryjnie zatrzymany w trakcie działania systemu):
\begin{minted}[mathescape,
               linenos,
               numbersep=5pt,
               %frame=lines,
               framesep=3mm,
               xleftmargin=21pt,
               breaklines,
               fontsize=\footnotesize]{js}
{'name': 'jtoy/awesome-tensorflow', 'url': 'https://github.com/jtoy/awesome-tensorflow', 'score': 0.91692072}
{'name': 'tensorflow/skflow', 'url': 'https://github.com/tensorflow/skflow', 'score': 0.88495779}
{'name': 'deepmind/sonnet', 'url': 'https://github.com/deepmind/sonnet', 'score': 0.88260406}
{'name': 'tensorflow/tensorflow', 'url': 'https://github.com/tensorflow/tensorflow', 'score': 0.87205422}
{'name': 'astorfi/TensorFlow-World', 'url': 'https://github.com/astorfi/TensorFlow-World', 'score': 0.8399685}
{'name': 'tensorflow/models', 'url': 'https://github.com/tensorflow/models', 'score': 0.8325097}
{'name': 'nfmcclure/tensorflow_cookbook', 'url': 'https://github.com/nfmcclure/tensorflow_cookbook', 'score': 0.76908624}
{'name': 'tensorflow/fold', 'url': 'https://github.com/tensorflow/fold', 'score': 0.76521885}
{'name': 'tflearn/tflearn', 'url': 'https://github.com/tflearn/tflearn', 'score': 0.75520557}
{'name': 'tensorflow/serving', 'url': 'https://github.com/tensorflow/serving', 'score': 0.72587609}
{'name': 'samjabrahams/tensorflow-on-raspberry-pi', 'url': 'https://github.com/samjabrahams/tensorflow-on-raspberry-pi', 'score': 0.72068191}
{'name': 'tensorflow/swift', 'url': 'https://github.com/tensorflow/swift', 'score': 0.7169168}
{'name': 'vahidk/EffectiveTensorflow', 'url': 'https://github.com/vahidk/EffectiveTensorflow', 'score': 0.69827163}
{'name': 'leriomaggio/deep-learning-keras-tensorflow', 'url': 'https://github.com/leriomaggio/deep-learning-keras-tensorflow', 'score': 0.69624388}
{'name': 'pkmital/tensorflow_tutorials', 'url': 'https://github.com/pkmital/tensorflow_tutorials', 'score': 0.65139794}
{'name': 'chiphuyen/stanford-tensorflow-tutorials', 'url': 'https://github.com/chiphuyen/stanford-tensorflow-tutorials', 'score': 0.63101554}
{'name': 'aymericdamien/TensorFlow-Examples', 'url': 'https://github.com/aymericdamien/TensorFlow-Examples', 'score': 0.62967598}
{'name': 'jostmey/NakedTensor', 'url': 'https://github.com/jostmey/NakedTensor', 'score': 0.6064766}
{'name': 'CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial', 'url': 'https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial', 'score': 0.60384893}
{'name': 'ethereon/caffe-tensorflow', 'url': 'https://github.com/ethereon/caffe-tensorflow', 'score': 0.5912745}

\end{minted}
\end{landscape}

\end{document}